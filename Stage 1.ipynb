{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ffa1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biom-format in /Users/sharyu/anaconda3/lib/python3.10/site-packages (2.1.15)\r\n",
      "Requirement already satisfied: click in /Users/sharyu/anaconda3/lib/python3.10/site-packages (from biom-format) (8.0.4)\r\n",
      "Requirement already satisfied: numpy>=1.9.2 in /Users/sharyu/anaconda3/lib/python3.10/site-packages (from biom-format) (1.23.5)\r\n",
      "Requirement already satisfied: scipy>=1.3.1 in /Users/sharyu/anaconda3/lib/python3.10/site-packages (from biom-format) (1.10.0)\r\n",
      "Requirement already satisfied: pandas>=0.20.0 in /Users/sharyu/anaconda3/lib/python3.10/site-packages (from biom-format) (1.5.3)\r\n",
      "Requirement already satisfied: h5py in /Users/sharyu/anaconda3/lib/python3.10/site-packages (from biom-format) (3.7.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/sharyu/anaconda3/lib/python3.10/site-packages (from pandas>=0.20.0->biom-format) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sharyu/anaconda3/lib/python3.10/site-packages (from pandas>=0.20.0->biom-format) (2022.7)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/sharyu/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.20.0->biom-format) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install biom-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d78dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for google colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b1e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biom import load_table\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import export_text\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import chi2,SelectKBest\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70f7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2bca52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BIOM file\n",
    "biom_file = path + '/Data/samples_10000_frequency_filtered.biom'\n",
    "table = load_table(biom_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be0f455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45532 x 951 <class 'biom.table.Table'> with 231299 nonzero entries (0% dense)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(table.ids())\n",
    "# print(table.filter)\n",
    "# obs = table.ids(axis='observation')\n",
    "# print(obs)\n",
    "# np.savetxt('obss.txt', obs, fmt='%s')\n",
    "# print(table.head(10))\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47bae8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#SampleID</th>\n",
       "      <th>subset_diabetes</th>\n",
       "      <th>host_taxid</th>\n",
       "      <th>allergic_to_unspecified</th>\n",
       "      <th>qiita_study_id</th>\n",
       "      <th>host_common_name</th>\n",
       "      <th>non_food_allergies_sun</th>\n",
       "      <th>physical_specimen_remaining</th>\n",
       "      <th>alcohol_types_unspecified</th>\n",
       "      <th>body_site</th>\n",
       "      <th>...</th>\n",
       "      <th>allergic_to_i_have_no_food_allergies_that_i_know_of</th>\n",
       "      <th>taxon_id</th>\n",
       "      <th>subset_bmi</th>\n",
       "      <th>description</th>\n",
       "      <th>non_food_allergies_drug_eg_penicillin</th>\n",
       "      <th>subset_healthy</th>\n",
       "      <th>env_feature</th>\n",
       "      <th>body_habitat</th>\n",
       "      <th>public</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10317.000074244.69032</td>\n",
       "      <td>True</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10317.0</td>\n",
       "      <td>human</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>408170.0</td>\n",
       "      <td>False</td>\n",
       "      <td>American Gut Project Stool sample</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>human-associated habitat</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>Yes</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10317.000097250.74745</td>\n",
       "      <td>True</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10317.0</td>\n",
       "      <td>human</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>408170.0</td>\n",
       "      <td>True</td>\n",
       "      <td>American Gut Project Stool sample</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>human-associated habitat</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>Yes</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10317.000037974.57180</td>\n",
       "      <td>True</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>10317.0</td>\n",
       "      <td>human</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>408170.0</td>\n",
       "      <td>True</td>\n",
       "      <td>American Gut Project Stool Sample</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>human-associated habitat</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10317.000110314.76911</td>\n",
       "      <td>False</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10317.0</td>\n",
       "      <td>human</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>408170.0</td>\n",
       "      <td>False</td>\n",
       "      <td>American Gut Project Stool sample</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>human-associated habitat</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>Yes</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10317.000051141.58828</td>\n",
       "      <td>True</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>10317.0</td>\n",
       "      <td>human</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>408170.0</td>\n",
       "      <td>True</td>\n",
       "      <td>American Gut Project Stool Sample</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>human-associated habitat</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>10317.000054290.59891</td>\n",
       "      <td>True</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>10317.0</td>\n",
       "      <td>human</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>408170.0</td>\n",
       "      <td>True</td>\n",
       "      <td>American Gut Project Stool Sample</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>human-associated habitat</td>\n",
       "      <td>UBERON:feces</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  #SampleID subset_diabetes  host_taxid  \\\n",
       "0     10317.000074244.69032            True      9606.0   \n",
       "1     10317.000097250.74745            True      9606.0   \n",
       "2     10317.000037974.57180            True      9606.0   \n",
       "3     10317.000110314.76911           False      9606.0   \n",
       "4     10317.000051141.58828            True      9606.0   \n",
       "...                     ...             ...         ...   \n",
       "1214  10317.000054290.59891            True      9606.0   \n",
       "1215                    NaN             NaN         NaN   \n",
       "1216                    NaN             NaN         NaN   \n",
       "1217                    NaN             NaN         NaN   \n",
       "1218                    NaN             NaN         NaN   \n",
       "\n",
       "     allergic_to_unspecified  qiita_study_id host_common_name  \\\n",
       "0                         No         10317.0            human   \n",
       "1                         No         10317.0            human   \n",
       "2                       TRUE         10317.0            human   \n",
       "3                         No         10317.0            human   \n",
       "4                      FALSE         10317.0            human   \n",
       "...                      ...             ...              ...   \n",
       "1214                   FALSE         10317.0            human   \n",
       "1215                     NaN             NaN              NaN   \n",
       "1216                     NaN             NaN              NaN   \n",
       "1217                     NaN             NaN              NaN   \n",
       "1218                     NaN             NaN              NaN   \n",
       "\n",
       "     non_food_allergies_sun physical_specimen_remaining  \\\n",
       "0                        No                         Yes   \n",
       "1                        No                         Yes   \n",
       "2                     FALSE                        TRUE   \n",
       "3                        No                         Yes   \n",
       "4                     FALSE                        TRUE   \n",
       "...                     ...                         ...   \n",
       "1214                  FALSE                        TRUE   \n",
       "1215                    NaN                         NaN   \n",
       "1216                    NaN                         NaN   \n",
       "1217                    NaN                         NaN   \n",
       "1218                    NaN                         NaN   \n",
       "\n",
       "     alcohol_types_unspecified     body_site  ...  \\\n",
       "0                           No  UBERON:feces  ...   \n",
       "1                           No  UBERON:feces  ...   \n",
       "2                        FALSE  UBERON:feces  ...   \n",
       "3                          Yes  UBERON:feces  ...   \n",
       "4                        FALSE  UBERON:feces  ...   \n",
       "...                        ...           ...  ...   \n",
       "1214                     FALSE  UBERON:feces  ...   \n",
       "1215                       NaN           NaN  ...   \n",
       "1216                       NaN           NaN  ...   \n",
       "1217                       NaN           NaN  ...   \n",
       "1218                       NaN           NaN  ...   \n",
       "\n",
       "     allergic_to_i_have_no_food_allergies_that_i_know_of  taxon_id subset_bmi  \\\n",
       "0                                                   Yes   408170.0      False   \n",
       "1                                                   Yes   408170.0       True   \n",
       "2                                                 FALSE   408170.0       True   \n",
       "3                                                   Yes   408170.0      False   \n",
       "4                                                 FALSE   408170.0       True   \n",
       "...                                                 ...        ...        ...   \n",
       "1214                                               TRUE   408170.0       True   \n",
       "1215                                                NaN        NaN        NaN   \n",
       "1216                                                NaN        NaN        NaN   \n",
       "1217                                                NaN        NaN        NaN   \n",
       "1218                                                NaN        NaN        NaN   \n",
       "\n",
       "                            description non_food_allergies_drug_eg_penicillin  \\\n",
       "0     American Gut Project Stool sample                                    No   \n",
       "1     American Gut Project Stool sample                                    No   \n",
       "2     American Gut Project Stool Sample                                  TRUE   \n",
       "3     American Gut Project Stool sample                                    No   \n",
       "4     American Gut Project Stool Sample                                 FALSE   \n",
       "...                                 ...                                   ...   \n",
       "1214  American Gut Project Stool Sample                                 FALSE   \n",
       "1215                                NaN                                   NaN   \n",
       "1216                                NaN                                   NaN   \n",
       "1217                                NaN                                   NaN   \n",
       "1218                                NaN                                   NaN   \n",
       "\n",
       "     subset_healthy               env_feature  body_habitat public     sex  \n",
       "0             False  human-associated habitat  UBERON:feces    Yes  female  \n",
       "1             False  human-associated habitat  UBERON:feces    Yes    male  \n",
       "2              True  human-associated habitat  UBERON:feces   TRUE    male  \n",
       "3             False  human-associated habitat  UBERON:feces    Yes  female  \n",
       "4             False  human-associated habitat  UBERON:feces   TRUE    male  \n",
       "...             ...                       ...           ...    ...     ...  \n",
       "1214           True  human-associated habitat  UBERON:feces   TRUE  female  \n",
       "1215            NaN                       NaN           NaN    NaN     NaN  \n",
       "1216            NaN                       NaN           NaN    NaN     NaN  \n",
       "1217            NaN                       NaN           NaN    NaN     NaN  \n",
       "1218            NaN                       NaN           NaN    NaN     NaN  \n",
       "\n",
       "[1219 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load metadata\n",
    "metadata = path + '/Data/metadata_filtered.txt'\n",
    "md = pd.read_csv(metadata, sep = '\\t')\n",
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6fed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1214    0.0\n",
      "1215    NaN\n",
      "1216    NaN\n",
      "1217    NaN\n",
      "1218    NaN\n",
      "Name: cardiovascular_disease, Length: 1219, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "md[\"cardiovascular_disease\"] = md[\"cardiovascular_disease\"].map({\"Diagnosed by a medical professional (doctor, physician assistant)\": 1, \"I do not have this condition\": 0})\n",
    "print(md[\"cardiovascular_disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32bf1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the table to a DataFrame\n",
    "# data = pd.DataFrame(table.matrix_data.toarray(),\n",
    "#                     index=table.ids(axis='observation'),\n",
    "#                     columns=table.ids(axis='sample'))\n",
    "\n",
    "\n",
    "\n",
    "data = pd.DataFrame(table.matrix_data.toarray().T, columns=table.ids(axis='observation'))\n",
    "data['SampleID'] = table.ids(axis='sample')\n",
    "data = data.sort_values(by='SampleID')\n",
    "md = md.sort_values(by='#SampleID')\n",
    "md = md.reset_index(drop=True)\n",
    "\n",
    "# Drop duplicate SampleID values from data\n",
    "data = data.drop_duplicates('SampleID')\n",
    "md = md.drop_duplicates('#SampleID')\n",
    "\n",
    "\n",
    "data['CVD'] = data['SampleID'].map(md.set_index('#SampleID')['cardiovascular_disease'])\n",
    "\n",
    "data\n",
    "# Display the updated DataFrame\n",
    "final_data = data.drop('SampleID',axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cca0fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = final_data.drop('CVD', axis=1)\n",
    "y = final_data['CVD']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed519834",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6601f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.548951048951049\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.60      0.56       135\n",
      "         1.0       0.58      0.50      0.54       151\n",
      "\n",
      "    accuracy                           0.55       286\n",
      "   macro avg       0.55      0.55      0.55       286\n",
      "weighted avg       0.55      0.55      0.55       286\n",
      "\n",
      "Specificity: 0.55\n",
      "Sensitivity: 0.55\n"
     ]
    }
   ],
   "source": [
    "#Create a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Extract specificity and sensitivity from the classification report\n",
    "specificity = report.split()[-4]\n",
    "sensitivity = report.split()[-2]\n",
    "\n",
    "# Print specificity and sensitivity\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f07aa7",
   "metadata": {},
   "source": [
    "# Elastic Net Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b2429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5734265734265734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.62      0.58       135\n",
      "         1.0       0.61      0.53      0.57       151\n",
      "\n",
      "    accuracy                           0.57       286\n",
      "   macro avg       0.58      0.58      0.57       286\n",
      "weighted avg       0.58      0.57      0.57       286\n",
      "\n",
      "Sensitivity: 0.5298013245033113\n",
      "Specificity: 0.6222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharyu/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+01, tolerance: 1.662e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Create an Elastic Net classifier\n",
    "clf_elastic_net = ElasticNet()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf_elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_elastic_net = clf_elastic_net.predict(X_test)\n",
    "\n",
    "# Convert the continuous predictions to binary class labels\n",
    "y_pred_binary = (y_pred_elastic_net > 0.5).astype(int)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calculate the sensitivity and specificity\n",
    "true_positive = sum((y_pred_binary == 1) & (y_test == 1))\n",
    "false_positive = sum((y_pred_binary == 1) & (y_test == 0))\n",
    "true_negative = sum((y_pred_binary == 0) & (y_test == 0))\n",
    "false_negative = sum((y_pred_binary == 0) & (y_test == 1))\n",
    "\n",
    "sensitivity = true_positive / (true_positive + false_negative)\n",
    "specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test, y_pred_binary)\n",
    "print(classification_rep)\n",
    "\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcba3c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. -0.  0. ... -0. -0.  0.]\n",
      "\n",
      "0.4418947995595818\n",
      "\n",
      "[0.97149367 0.47914148 0.22149031 0.11575097 0.5263735  0.95158618\n",
      " 0.39725961 0.73431284 0.14282735 0.8503161 ]\n",
      "\n",
      "0.8354148738040013\n",
      "\n",
      "-1.8004366768831126\n"
     ]
    }
   ],
   "source": [
    "print(clf_elastic_net.coef_)\n",
    "print( )\n",
    "print(clf_elastic_net.intercept_)\n",
    "print( )\n",
    "print(clf_elastic_net.predict(X_train)[:10])\n",
    "print( )\n",
    "print(np.sqrt(mean_squared_error(y_test,y_pred_elastic_net)))\n",
    "print( )\n",
    "print(r2_score(y_test,y_pred_elastic_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2f50d",
   "metadata": {},
   "source": [
    "# Neural Networks Classifier (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa80aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5699300699300699\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.53      0.54       135\n",
      "         1.0       0.59      0.61      0.60       151\n",
      "\n",
      "    accuracy                           0.57       286\n",
      "   macro avg       0.57      0.57      0.57       286\n",
      "weighted avg       0.57      0.57      0.57       286\n",
      "\n",
      "Specificity: 0.57\n",
      "Sensitivity: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Create a Neural Networks (Multi-Layer Perceptron) classifier\n",
    "clf_neural_net = MLPClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf_neural_net.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_neural_net = clf_neural_net.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred_neural_net)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(y_test, y_pred_neural_net)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Extract specificity and sensitivity from the classification report\n",
    "specificity = report.split()[-4]\n",
    "sensitivity = report.split()[-2]\n",
    "\n",
    "# Print specificity and sensitivity\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d214a",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42010e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.548951048951049\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.76      0.61       135\n",
      "         1.0       0.62      0.36      0.46       151\n",
      "\n",
      "    accuracy                           0.55       286\n",
      "   macro avg       0.57      0.56      0.54       286\n",
      "weighted avg       0.57      0.55      0.53       286\n",
      "\n",
      "Specificity: 0.57\n",
      "Sensitivity: 0.53\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest classifier\n",
    "clf_random_forest = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf_random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_random_forest = clf_random_forest.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred_random_forest)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(y_test, y_pred_random_forest)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Extract specificity and sensitivity from the classification report\n",
    "specificity = report.split()[-4]\n",
    "sensitivity = report.split()[-2]\n",
    "\n",
    "# Print specificity and sensitivity\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548431e3",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed615d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.506993006993007\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.87      0.63       135\n",
      "         1.0       0.61      0.18      0.28       151\n",
      "\n",
      "    accuracy                           0.51       286\n",
      "   macro avg       0.55      0.53      0.45       286\n",
      "weighted avg       0.55      0.51      0.44       286\n",
      "\n",
      "Specificity: 0.55\n",
      "Sensitivity: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Create a Support Vector Machine (SVM) classifier\n",
    "clf_svm = SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(y_test, y_pred_svm)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Extract specificity and sensitivity from the classification report\n",
    "specificity = report.split()[-4]\n",
    "sensitivity = report.split()[-2]\n",
    "\n",
    "# Print specificity and sensitivity\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
